{
    "model": "gpt-4o",
    "temperature": 0.01,
    "max_tokens": 16384
} 
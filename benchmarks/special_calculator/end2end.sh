mcp-eval generate-tasks --server mcp_servers/special_calculator/server.py --model gpt-4.1-2025-04-14 --max-tokens 4000 --temperature 0.2 --num-tasks 2 --prompt-file benchmarks/special_calculator/data_generation/task_generation_prompt.json --output data/special_calculator/evaluation_tasks.jsonl
mcp-eval verify-tasks --server mcp_servers/special_calculator/server.py --tasks-file data/special_calculator/evaluation_tasks.jsonl --model gpt-4.1-2025-04-14 --output data/special_calculator/evaluation_tasks_verified.jsonl --prompt-file benchmarks/special_calculator/data_generation/task_verification_prompt.json
# evaluate gpt-4o-mini
mcp-eval evaluate --server mcp_servers/special_calculator/server.py --model-config benchmarks/special_calculator/eval_models/gpt-4o-mini.json --tasks-file data/special_calculator/evaluation_tasks_verified.jsonl --output benchmarks/special_calculator/results/gpt4o-mini_task_evaluation.json --prompt-file benchmarks/special_calculator/evaluation_prompt.json --max-turns 30
mcp-eval analyze --predictions benchmarks/special_calculator/results/gpt4o-mini_task_evaluation.json --ground-truth data/special_calculator/evaluation_tasks_verified.jsonl --generate-report --report-model gpt-4.1-2025-04-14 --report-output benchmarks/special_calculator/report/gpt4o-mini_evaluation_tasks_verified_report.md